{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN으로 CIFAR10 이미지 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 불러오기\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(train_x, _), (test_x, _) = cifar10.load_data()\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # First : Dense layer\n",
    "    model.add(layers.Dense(7*7*256, use_bias = False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # Second : Reshape Layer\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    \n",
    "    # Third : Conv2DTranspose Layer\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size = (5, 5), strides=(1, 1), padding='same', use_bias = False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # Fourth : Conv2DTranspose Layer\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias = False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # Fifth : Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image = generator(noise, training=False)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    \n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # First : Conv2D layer\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Second Conv2D Layer\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Third : flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Fourth : Dense Layer\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.00081154]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision = discriminator(generated_image, training=False)\n",
    "decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_accuracy(real_output, fake_output):\n",
    "    real_accuracy = tf.reduce_mean(tf.cast(tf.math.greater_equal(real_output, tf.constant([0.5])), tf.float32))\n",
    "    fake_accuracy = tf.reduce_mean(tf.cast(tf.math.less(fake_output, tf.constant([0.5])), tf.float32))\n",
    "    return real_accuracy, fake_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images): # (1) 입력 데이터\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim]) # (2) 생성자 입력 노이즈\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # (3) tf.GradientTape() 오픈\n",
    "        generatoed_images = generator(noise, training=True) # (4) geerated_images 생성\n",
    "        \n",
    "        # (5) discriminator 판별\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        # (6) loss 개선\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # (7) accuracy 계산\n",
    "        real_accuracy, fake_accuracy = discriminator_accuracy(real_output, fake_output)\n",
    "    \n",
    "    # (8) gradient 계산\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # (9) 모델 학습\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss, real_accuracy, fake_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, it, sample_seeds):\n",
    "    \n",
    "    predictions = model(sample_seeds, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize = (4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.savefig('./data/generated_samples/sample_epoch_{:04d}_iter_{:03d}.png'.format(epoch, it))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6    # matlab 차트의 기본 크기를 15,6으로 지정해 줍니다.\n",
    "\n",
    "def draw_train_history(history, epoch):\n",
    "    # summarize history for loss  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history['gen_loss'])  \n",
    "    plt.plot(history['disc_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['gen_loss', 'disc_loss'], loc='upper left')  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history['fake_accuracy'])  \n",
    "    plt.plot(history['real_accuracy'])  \n",
    "    plt.title('discriminator accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['fake_accuracy', 'real_accuracy'], loc='upper left')  \n",
    "    \n",
    "    # training_history 디렉토리에 epoch 별로 그래프를 이미지 파일로 저장합니다.\n",
    "    plt.savefig('./data/training_history/train_history_{:04d}.png'.format(epoch))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './data/training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
