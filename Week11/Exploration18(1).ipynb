{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 요약봇 만들기\n",
    "\n",
    "\n",
    "## 텍스트 요약 (Text Summarization)이란?\n",
    "\n",
    "![img](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-21-1.png)\n",
    "\n",
    "텍스트 요약(Text Summarization)이란 위 그림과 같이 긴 길이의 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환한 것을 말합니다. 예를 들어 상대적으로 큰 텍스트인 뉴스 기사로 작은 텍스트인 뉴스 제목을 만들어내는 것이 텍스트 요약의 대표적인 예라고 할 수 있습니다.\n",
    "\n",
    "이 때 중요한 것은 요약 전후에 정보 손실 발생이 최소화 되어야 한다는 점입니다. 이것은 정보를 압축하는 과정과 같습니다. 비록 텍스트의 길이가 크게 줄어들었지만, 요약문은 문서의 원문이 담고 있는 정보를 최대한 보존하고 있어야 합니다. 이것은 원문의 길이가 길수록 만만치 않은 어려운 작업이 됩니다. 사람이 이 작업을 수행한다 하더라도 긴 문장을 정확하게 읽고 이해한 후, 그 의미를 손상하지 않는 짧은 다른 표현으로 원문을 번역해 내야하는 것입니다.\n",
    "\n",
    "그렇게 요약 문장을 만들어 내려면 어떤 방법을 사용하는 것이 좋을까요? 여기서 텍스트 요약은 크게 **추출적 요약(Extractive Summarization)**과 **추상적 요약(Abstractive Summarization)**의 두가지 접근으로 나누어볼 수 있습니다.\n",
    "\n",
    "### 추출적 요약 (Extractive Summarization)\n",
    "\n",
    "첫 번째 방식인 추출적 요약은 단어 그대로 원문에서 문장들을 추출해서 요약하는 방식입니다. 가령, 10개의 문장으로 구성된 텍스트가 있다면 그 중 핵심적인 문장 3개를 꺼내와서 3개의 문장으로 구성된 요약문을 만드는 식입니다. 그런데 꺼내온 3개의 문장이 원문에서 중요한 문장일 수는 있어도, 3개의 문장의 연결이 자연스럽지 않을 수 있습니다. 결과로 나온 문장들 간의 호응지 자연스럽지 않을 수 있다는 것이죠. 딥러닝보다는 주로 전통적인 머신 러닝 방식에 속하는 텍스트랭크([TextRank](https://www.aclweb.org/anthology/W04-3252.pdf))와 같은 알고리즘을 사용해서 이 방법을 사용한다고 합니다.\n",
    "\n",
    "이런 방식을 이미 서비스에 도입해서 활용하고 있는 사례가 있습니다. 가장 대표적인 것이 네이버 뉴스의 요약봇입니다. \n",
    "\n",
    "![img](http://img.hani.co.kr/imgdb/resize/2017/1210/00501972_20171210.JPG)\n",
    "\n",
    "[네이버 뉴스](https://news.naver.com/)에 접속해서 아무 뉴스 기사나 클릭하면 제목 우하단에 `요약봇` 버튼이 있습니다. 기사 원문을 요약한 글을 보실 수 있으실 겁니다. 가끔 세 문장간 연결이 조금 매끄럽지 않게 느껴질때도 있지만 꽤 그럴듯한 요약문을 보이고 있습니다. 위에서 소개한 TextRank 알고리즘을 통해 해당 기사를 가장 잘 대표하는 단어들로 이루어진 핵심 문장을 아주 효과적으로 찾아내기 때문입니다. 잘 찾아보면 요약문에 사용된  문장 3개가 원문에 그대로 있다는 것을 알 수 있을 것입니다.\n",
    "\n",
    "### 추상적 요약(Abstractive Summarization)\n",
    "\n",
    "두 번째 방식인 추상적 요약은 추출적 요약보다 좀 더 흥미로운 접근을 사용합니다. 원문으로부터 내용이 요약된 *새로운 문장을 생성*해내는 것이죠. 여기서 새로운 문장이라는 것은 결과로 나온 문장이 원문에 원래 없던 문장일수도 있다는 것을 의미합니다. 자연어 처리 분야 중 자연어 생성(Natural Language Generation, NLG)의 영역인 셈입니다. 반면, 추출적 요약은 원문을 구성하는 문장 중 어느 것이 요약문에 들어갈 핵심 문장인지를 판별한다는 점에서 문장 분류(Text Classification) 문제로 볼 수 있을 것입니다.\n",
    "\n",
    "자연어 생성하면 떠오르는 신경망들이 있습니다. RNN.. LSTM.. \n",
    "\n",
    "그저 RNN을 이용해 Language Generation을 한다고 해서 긴 문장을 읽고 나서 요약문을 뚝딱 만들어내긴 어렵습니다.  한번 아래 기사를 가볍게 읽고 다음으로 넙어가봅시다.\n",
    "\n",
    "- [구글 인공지능, \"뉴스 제목도 잘 뽑네\"](https://zdnet.co.kr/view/?no=20160905114833&from=Mobile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "우리는 seq2seq 모델을 통해서 Abstractive summarization 방식의 텍스트 요약기를 만들어 볼 것입니다. seq2seq는 두 개의 RNN 아키텍처를 사용하여 입력 시퀀스로부터 출력 시퀀스를 생성해내는 자연어 생성 모델입니다. 주료 뉴럴 기계 번역에 사용되는 이 모델이 텍스트 요약에도 사용할 수 있다니 조금 새로비만, 원문을 요약문으로 번역한다고 생각하면 전혀 무리가 없겠죠?\n",
    "\n",
    "### seq2seq 개요\n",
    "\n",
    "![Img](https://aiffelstaticprd.blob.core.windows.net/media/images/E-21-2.max-800x600.png)\n",
    "\n",
    "원문을 첫번째 RNN인 인코더로 입력하면, 인코더는 이를 하나의 고정된 벡터로 변환합니다. 이 벡터를 문맥 정보를 가지고 있는 벡터라 하여 컨텍스트 벡터(context vector)라고 합니다. 두번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한 단어씩 생성해내서 요약 문장을 완성합니다.\n",
    "\n",
    "### LSTM과 컨텍스트 벡터\n",
    "\n",
    "우리는 seq2seq를 구현할 때, 인코더/디코더로 바닐라 RNN이 아니라 LSTM을 사용할 것입니다.\n",
    "\n",
    "![Img](https://aiffelstaticprd.blob.core.windows.net/media/images/E-21-3.max-800x600.png)\n",
    "\n",
    "LSTM이 바닐라RNN과 다른 점은 다음 time step의 셸에 hidden state 뿐만 아니라 cell state도 함께 전달한다는 점입니다. 다시 말해, 인코더가 디코더에 전달하는 컨텍스트 벡터 또한 hidden state h와 cell state c 두 개의 값 모두 존재해야 한다는 뜻입니다.\n",
    "\n",
    "### 시작 토큰과 종료 토큰\n",
    "\n",
    "![img](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-21-4.png)\n",
    "\n",
    "seq2seq 구조에서 디코더는 시작 토큰 SOS가 입력되면 각 시점마다 단어를 생성하고 이 과정을 종료 토큰 EOS를 예측하는 순간까지 멈추지 않습니다. 다시 말해 훈련 데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작 토큰과 종료 토큰을 넣어주는 전처리를 통해 어디서 멈춰야하는지 알려줄 필요가 있습니다.\n",
    "\n",
    "### 어텐션 메커니즘을 통한 새로운 컨텍스트 벡터 사용하기\n",
    "\n",
    "![img](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-21-5.png)\n",
    "\n",
    "우리는 기존에 배운 seq2seq를 수정하고, 새로운 모듈을 붙여 모델의 성능을 높여볼 것입니다. 기존의 seq2seq는 **인코더의 마지막 time step의 hidden state**를 컨텐스트 벡터로 사용했습니다. 하지만 RNN 계열의 인공 신경망(바닐라 RNN, LSTM, GRU)의 한계로 인해 이 컨텍스트 정보에는 이미 입력 시퀀스의 많은 정보가 손실이 된 상태가 됩니다.\n",
    "\n",
    "**어텐션 메커니즘(Attention Mechanism)**은 이와 달리, **인코더의 모든 step의 hidden state의 정보**가 컨텍스트 벡터에 전부 반영이 되도록 하는 것입니다. 하지만 인코더의 모든 hidden state가 동일한 비중으로 반영되는 것이 아니라, 디코더가 *현재 time step*의 예측에 인코더의 각 step이 얼마나 영향을 미치는지에 따른 가중합으로 계산되는 방식입니다.\n",
    "\n",
    "위의 그림을 예로 들자면, seq2seq 모델이라면 디코더로 전달되는 인코더의 컨텍스트 벡터는 인코더의 마지막 스텝의 hidden state인 $h_5$가 되겠지만 어텐션 메커니즘이 적용된 seq2seq인 Attentional seq2seq이라면 인코더의 컨텍스트 벡터는 예를 들어 $0.2h_1 + 0.3h_2 + 0.15h_4 + 0.25h_5$가 될 수도 있는 것입니다.\n",
    "\n",
    "여기서 주의해야 할 것은, 컨텍스트 벡터를 구성하기 위한 인코더 hidden state의 가중치 값은 **디코더의 현재 스텝이 어디냐에 따라 계속 달라진다**는 점입니다. 즉, 디코더의 현재 문장 생성 부위가 주어부인지 술어부인지 목적어인지 등에 따라 인코더가 입력 데이터를 해석한 컨텍스트 벡터가 다른 값이 된다는 것입니다. 이와 달리, 기본적인 seq2seq 모델에서 컨텍스트 벡터는 디코더의 현재 스텝 위치에 무관하게 한번 계산되면 고정 값을 가집니다.\n",
    "\n",
    "이렇게 디코더의 현재 스텝에 따라 동적으로 달라지는 인코더의 컨텍스트 벡터를 사용해서 현재의 예측을 활용하면, 디코더가 좀 더 정확한 예측을 할 수 있게 됩니다. 이러한 Attention 기법은 seq2seq를 비록하여 향후 딥러닝 분야를 획기적으로 발전시킨 개념이 됩니다. 특히 자연어처리 분야에서는 두말할 것도 없겠죠? 아직은 Attention 개념이 명확하게 와닿지 않을지라도 앞으로도 수차례에 걸쳐 이 개념에 대해 더욱 깊이있게 다루게 될 것입니다.\n",
    "\n",
    "지금까지의 내용을 정리해봅시다.\n",
    "\n",
    "1. seq2seq를 사용한다.\n",
    "2. RNN 계열 중 LSTM을 사용해야 하므로 hidden state 뿐만 아니라 cell state도 사용해야 합니다.\n",
    "3. 디코더의 예측 시퀀스에는 시작 토큰 SOS와 예측 토큰 EOS를 시퀀스의 앞, 뒤로 붙입니다.\n",
    "4. seq2seq를 구동시키면 디코더는 시작 토큰을 입력받아 예측을 시작합니다.\n",
    "5. seq2seq 기본 모델과 달리, 어텐션 메커니즘을 이용해 인코더의 hidden state의 중요도를 취합한 컨텍스트 벡터를 디코더 스텝별로 계산합니다.\n",
    "6. 계산된 컨텍스트 벡터를 이용해서 디코더는 다음 등장할 단어를 예측합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비하기\n",
    "\n",
    "이제 데이터를 준비해봅시다. 오늘 우리가 텍스트 요약 모델 학습에 사용할 데이터셋은 kaggle에서 제공된 **아마존 리뷰 데이터셋**입니다.\n",
    "\n",
    "<https://www.kaggle.com/snap/amazon-fine-food-reviews>\n",
    "\n",
    "위 링크에서 `Reviews.csv`파일을 다운로드 받아 `./data` 폴더로 이동해주세요. \n",
    "\n",
    "이번 실습에서는 NLTK의 불용어(stopworkds)를 사용할 것입니다. NTLK와 NLTK의 데이터셋이 설치되어있지 않다면 아래 명령어로 우선 NLTK를 설치하고 NTLK의 데이터셋을 다운로드해주세요. \n",
    "\n",
    "NLTK는 Natural Language Toolkit의 축약어로, 영어기호, 통계, 자연어 처리를 위한 라이브러리입니다. 이 NLTK애는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장하지만 의미를 분석하고 요약하는 데에는 거의 의미가 없는 100여개의 불용어가 미리 정의되어 있습니다. 이를 이용해 다운로드받은 리뷰 파일에서 불용어를 제거하는 작업을 진행할 예정입니다.\n",
    "\n",
    "```bash\n",
    "$ pip install nltk\n",
    "```\n",
    "\n",
    "nltk 패키지에서 불용어 사전을 다운로드 받고, 데이터 전처리를 위한 나머지 패키지도 함께 불러와봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aiffel0039/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 가지고 있습니다. 시간상 여기서는 모든 샘플을 사용하지는 않고 간단히 10만개의 샘플만 사용해보겠습니다. 데이터 파일의 경로를 수정하는 것을 잊지마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 100000\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.dirname(os.path.abspath('__file__')) + r'/data/Reviews.csv'\n",
    "data = pd.read_csv(file_path, nrows=100000)\n",
    "print(\"전체 샘플 수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 이렇게 되어있습니다. 사실 전체 데이터 중 Summary 열과 Text 열만 훈련에 사용할 거라, 이 두개의 열만 별도로 저장하고 다시 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text', 'Summary']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95807</th>\n",
       "      <td>This cereal is pretty good, as far as healthy(...</td>\n",
       "      <td>Too much bland chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91445</th>\n",
       "      <td>I wrote a similar review for the other Peace c...</td>\n",
       "      <td>Just ok, too much sugar. Not organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39006</th>\n",
       "      <td>For anyone who remembers those fudgy little co...</td>\n",
       "      <td>Closest thing to 70s Girl Scout Fudge Patties ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>My synagogue's Passover Care Package had some ...</td>\n",
       "      <td>Passover treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76276</th>\n",
       "      <td>I love Jasmine tea! More than anyone trust me....</td>\n",
       "      <td>The Best of the Best!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40526</th>\n",
       "      <td>i ordered this tea to produce more breastmilk ...</td>\n",
       "      <td>horrible taste &amp; stinky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55165</th>\n",
       "      <td>I found this food in one local supermarket; ho...</td>\n",
       "      <td>Wonderful product for cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43349</th>\n",
       "      <td>the product I ordered was not the product that...</td>\n",
       "      <td>misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>I'm happy with the quality of the product and ...</td>\n",
       "      <td>Good oatmeal, I'm on my second bag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59882</th>\n",
       "      <td>I have found this to be a nice alternative to ...</td>\n",
       "      <td>tasty, but don't expect to lose weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Better than organic oats advertised elsewhere....</td>\n",
       "      <td>Good quality, delivered on time, human edible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75287</th>\n",
       "      <td>I have two older cats (10+ years) and one had ...</td>\n",
       "      <td>My Cats Liked it For a While</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>I bought several different brands of Chai from...</td>\n",
       "      <td>Best Chai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42136</th>\n",
       "      <td>My ordering the flour was quite easy. When I f...</td>\n",
       "      <td>Millet Flour, easy order, quick delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96575</th>\n",
       "      <td>The taste was good but it developed these huge...</td>\n",
       "      <td>Needs improvement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "95807  This cereal is pretty good, as far as healthy(...   \n",
       "91445  I wrote a similar review for the other Peace c...   \n",
       "39006  For anyone who remembers those fudgy little co...   \n",
       "3058   My synagogue's Passover Care Package had some ...   \n",
       "76276  I love Jasmine tea! More than anyone trust me....   \n",
       "40526  i ordered this tea to produce more breastmilk ...   \n",
       "55165  I found this food in one local supermarket; ho...   \n",
       "43349  the product I ordered was not the product that...   \n",
       "852    I'm happy with the quality of the product and ...   \n",
       "59882  I have found this to be a nice alternative to ...   \n",
       "828    Better than organic oats advertised elsewhere....   \n",
       "75287  I have two older cats (10+ years) and one had ...   \n",
       "27992  I bought several different brands of Chai from...   \n",
       "42136  My ordering the flour was quite easy. When I f...   \n",
       "96575  The taste was good but it developed these huge...   \n",
       "\n",
       "                                                 Summary  \n",
       "95807                           Too much bland chocolate  \n",
       "91445               Just ok, too much sugar. Not organic  \n",
       "39006  Closest thing to 70s Girl Scout Fudge Patties ...  \n",
       "3058                                      Passover treat  \n",
       "76276                              The Best of the Best!  \n",
       "40526                            horrible taste & stinky  \n",
       "55165                         Wonderful product for cats  \n",
       "43349                                         misleading  \n",
       "852                   Good oatmeal, I'm on my second bag  \n",
       "59882             tasty, but don't expect to lose weight  \n",
       "828       Good quality, delivered on time, human edible.  \n",
       "75287                       My Cats Liked it For a While  \n",
       "27992                                          Best Chai  \n",
       "42136           Millet Flour, easy order, quick delivery  \n",
       "96575                                  Needs improvement  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤한 3개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 하기 (1) - 데이터 정리하기\n",
    "\n",
    "이제 데이터를 불러왔으니 전처리를 진행해봅시다. 빈칸으로 존재하는 Null 데이터, 의미는 같지만 다른 식으로 작성된 글같은 중복 항목과 같은 학습할 때 방해가 되는 데이터를 먼저 솎아낼 것입니다.\n",
    "\n",
    "### 중복 샘플과 NULL값이 존재하는 샘플 제거\n",
    "\n",
    "우선 데이터의 중복 샘플 유무를 확인해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print(\"Text 열에서 중복을 배제한 유일한 샘플의 수 :\", data['Text'].nunique())\n",
    "print(\"Summary 열에서 중복을 배제한 유일한 샘플의 수 :\", data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복을 제외한다면 Text에는 88,426개, Summary에서는 72,348개의 유니크한 데이터가 존재합니다. 사실 이 데이터의 Summary는 'Smelly'나 'Good Product'와 같이 아주 간단한 요약들도 많아서 Text가 달라도 Summary는 동일할 수 있습니다. 하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거해야겠죠.\n",
    "\n",
    "데이터 프레임의 `drop_duplicates()`를 사용하면 손쉽게 중복 샘플을 제거할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 88426\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset=['Text'], inplace=True)\n",
    "print(\"전체 샘플 수 :\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복이 제거되면서 샘플 수가 88,426개로 줄어들었습니다. 그런데 만약 데이터 Null 값을 가지는 샘플이 있었다면, `drop_duplicates()`가 중복된 Null들을 지워주기는 하겠지만 여전히 Null 값 한개가 어딘가에 남아있을 수 있습ㄴ디ㅏ. 데이터에 Null값이 남아있는지 보겠습니다.\n",
    "\n",
    "데이터 프레임에 Null값이 있는지 확인하는 방법은 `.isnull().sum()`을 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text       0\n",
       "Summary    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary에 1개의 Null값이 있습니다. 데이터프레임에서 Null값을 제거할 때에는 `dropna()` 함수를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수: 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print(\"전체 샘플 수:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 샘플 수가 88.425개가 되었습니다. 지금까지 중복 샘플과 Null 값이 있는 샘플들을 제거해보았는데 10만개의 샘플 중 1만개 이상의 샘플이 제거되었습니다.\n",
    "\n",
    "\n",
    "### 텍스트 정규화와 불용어 제거\n",
    "\n",
    "살아남은 샘플에는 수많은 단어가 있습니다. 그런데 사실 그 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있습니다.\n",
    "\n",
    "예를들어 'it'll'은 'it will'과 같고, 'mustn't'과 'must not'은 같은 표현입니다. 이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법입니다.\n",
    "\n",
    "이러한 방법론을 텍스트 처리에서는 **텍스트 정규화(text normalization)**이라고 합니다.\n",
    "\n",
    "여기서는 텍스트 정규화를 위한 사전(dictionary)를 아래와 같이 구성할 것입니다. 이 사전은 [링크](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python)를 참고하여 만들었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화를 마쳤습니다.\n",
    "\n",
    "하지만 아직 끝나지 않았습니다. 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별로 도움이 되지 않는 단어들이 존재합니다. 이를 불용어(stopwords)라고 합니다. 때로는 불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법이 됩니다. 여기서는 NLTK에서 제공하는 불용어 리스트를 참조해 샘플에서 불용어를 제거할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어의 개수 :  179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"불용어의 개수 : \", len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개입니다. 이를 사용하여 불용어를 제거할거에요. 이 작업 외에도 모든 영어문자는 소문자로 만들고, 섞여있는 html 태그를 제거하고 정규표현식을 사용해 각종 특수문자를 제거해 정말 필요한 내용만 학습할 수 있도록 처리하겠습니다.\n",
    "\n",
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이른 Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 Summary 전처리를 할 때에는 호출하지 않을 예정입니다. Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 summary에는 남아있는 것이 더 좋을 것 같습니다. 이 처리를 위해 함수의 인자로 remove_stopwords를 추가하고 if문을 더해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').text # html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한번 그럼 테스트를 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 모든 알파벳이 소문자로 변환되고, html 태그도 제거되었습니다. 또한 (or finish)와 같은 괄호로 묶였던 단어 시퀀스가 제거된 것도 확인할 수 있습니다. 특수문자도 제거되면서 영어만 남았습니다.\n",
    "\n",
    "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행해봅시다. 이때 Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행해야 합니다. 먼저 Text를 전처리하고 결과를 확인하기 위해서 상위 5개 줄을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3016e85ad5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 전처리 후 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclean_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_test' is not defined"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 꽤 오래 걸릴 수 있습니다.\n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출할 때는, 불용어 제거를 수행하지 않는다는 의미에서 두번째 인자로 False를 넣어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0039/anaconda3/envs/aiffel/lib/python3.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 -> 5분 이상의 시간이 걸릴 수 있습니다.\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋습니다. 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있습니다. 이렇게 되면 샘플 자체가 빈값을 가지게 됩니다.\n",
    "\n",
    "보다 쉽게 확인하기 위해서 데이터들을 데이터프레임에 재저장하겠습니다. 그리고 빈(empty) 값을 가진 샘플들이 있다면 모두 Null값을 가진 샘플로 대체하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary 열에서 70개의 Null값이 생겼습니다. 원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미입니다. 이 샘플들은 모두 제거해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플 수 :', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (2) - 훈련 데이터와 테스트 데이터 나누기\n",
    "\n",
    "학습을 진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고 문장의 시작과 끝을 표시해줘야 합니다.\n",
    "\n",
    "### 샘플의 최대 길이 정하기\n",
    "\n",
    "필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차럐입니다.\n",
    "\n",
    "Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 :  2\n",
      "텍스트의 최대 길이 :  1235\n",
      "텍스트의 평균 길이 :  38.792428272310566\n",
      "요약의 최소 길이 :  1\n",
      "요약의 최대 길이 :  28\n",
      "요약의 평균 길이 :  4.010729443721352\n"
     ]
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print(\"텍스트의 최소 길이 : \", np.min(text_len))\n",
    "print(\"텍스트의 최대 길이 : \", np.max(text_len))\n",
    "print(\"텍스트의 평균 길이 : \", np.mean(text_len))\n",
    "print(\"요약의 최소 길이 : \", np.min(summary_len))\n",
    "print(\"요약의 최대 길이 : \", np.max(summary_len))\n",
    "print(\"요약의 평균 길이 : \", np.mean(summary_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title(\"Summary\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title(\"Text\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of sampels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프처럼 많은 양의 데이터를 다룰 때에는 데이터를 시각화하여 보는 것이 도움이 됩니다. 위에서 부터 차례대로 그래프는 각각의 요약과 실제 텍스트의 길이 분포, 요약본 샘플 길이별 갯수, 실제 텍스트 샘플 길이별 갯수를 나타내고 있습니다.\n",
    "\n",
    "Text의 경우 최소 길이가 2, 최대 길이가 1,235으로 그 차이가 굉장히 급니다. 하지만 평균 길이는 38로 시각화된 그래프로 봤을 때에는 대체적으로 100 내외의 길이를 가진다는 것을 확인할 수 있습니다.\n",
    "\n",
    "Summary의 경우 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧습니다. 그래프로 봤을 때에도 대체적으로 10 이하의 길이를 가지고 있습니다.\n",
    "\n",
    "이로부터 text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 깅리를 결정하는 데 도움이 될 것입니다. 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if len(s.split()) <= max_len:\n",
    "            cnt = cnt + 1\n",
    "    print(\"전체 샘플 중 길이가 {} 이하인 샘플의 비율 : {}\".format(max_len, (cnt/len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율 : 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율 : 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len, data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 50과 8로 패딩을 하게되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 망가지게 된다고 합니다.\n",
    "\n",
    "우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x : len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x : len(x.split()) <= summary_max_len)]\n",
    "print(\"전체 샘플 수 : \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "\n",
    "앞서 시작 토큰과 종료 토큰에 대해서 언급했습니다. 디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고 종료 토큰을 예측한 순간에 문장 생성을 멈추는 것이었습니다.\n",
    "\n",
    "![Img](https://aiffelstaticprd.blob.core.windows.net/media/original_images/E-21-4.png)\n",
    "\n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있습니다. 이번 실습에서는 시작 토큰은 `sostoken`, 종료 토큰은 `eostoken`이라고 임의로 명명하고 앞, 뒤로 추가하겠습니다. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 `decoder_input`, 디코더의 출력 또는 레이블에 해당하면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 `decoder_target`이라고 이름을 정하겠습니다. 두 개의 문장 모두 Summary 열로부터 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken ' + x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞뒤로 토큰이 잘 붙었습니다.\n",
    "\n",
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련 데이터와 테스트 데이터를 분리하겠습니다.\n",
    "\n",
    "훈련 데이터와 테스트 데이터를 분리하는 방법은 분리 패키지를 사용하는 방법, 또는 직접 코딩을 통해서 분리하는 방법 등 여러가지 방법이 있을텐데 여기서는 직접 해보도록 하겠습니다. 우선, `encoder_input`과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41143 15392   901 ... 18812 39111 52249]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해주면 잘 섞인 샘플이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 섞인 데이터를 8:2 비율로 훈련 데이터와 테스트 데이터로 분리해주겠습니다. 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input) * 0.2)\n",
    "print(\"테스트 데이터의 수 :\", n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 정의한 테스트 데이터의 갯수를 이용해 전체 데이터를 양분하겠습니다. ; 표기의 위치에 주의해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 갯수 : 52655\n",
      "훈련 레이블의 갯수 : 52655\n",
      "테스트 데이터의 갯수 : 13163\n",
      "테스트 데이터의 갯수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(\"훈련 데이터의 갯수 :\", len(encoder_input_train))\n",
    "print(\"훈련 레이블의 갯수 :\", len(decoder_input_train))\n",
    "print(\"테스트 데이터의 갯수 :\", len(encoder_input_test))\n",
    "print(\"테스트 데이터의 갯수 :\", len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (3) - 정수 인코딩\n",
    "\n",
    "\n",
    "### 단어 집합 (vocaburary) 만들기 및 정수 인코딩\n",
    "\n",
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어주어야 합니다. 이를 위해서는 각 단어에 고유한 정ㅅ로 맵핑하는 작업이 필요해요. 이 과정을 **단어 집합(vocaburary)**을 만든다고 표현합니다. 훈련 데이터에 대해서 단어 집합을 만들어보겠습니다. 우선, 원문에 해당되는 `encoder_input_train`에 대해서 단어 집합을 만들겠습니다.\n",
    "\n",
    "Keras의 토크나이저를 사용하면 입력된 훈련 데이터로부터 단어 집합을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 점수가 부여되었습니다. 현재 생성된 단어 집합은 `src_tokenizer.word_index`에 저장되어있습니다. 그렇지만 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 합니다.\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해보겠습니다. \n",
    "\n",
    "`src_tokenizer.word_counts.items()`에는 단어와 각 단어의 등장 빈도수가 저장되어져 있습니다. 이를 통해 통계적인 정보를 얻어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 :  32037\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수 : 23792\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 :  8245\n",
      "단어 집합에서 희귀 단어의 비율 :  74.26413209726253\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도의 비율 :  3.381656219433666\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold 보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "    \n",
    "    # 단어의 등장 빈도 수가 threshold보다 작으면\n",
    "    if value < threshold:\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "    \n",
    "\n",
    "print(\"단어 집합(vocabulary)의 크기 : \", total_cnt)\n",
    "print(\"등장 빈도가 {}번 이하인 희귀 단어의 수 : {}\".format(threshold-1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 : \", total_cnt - rare_cnt)\n",
    "print(\"단어 집합에서 희귀 단어의 비율 : \", (rare_cnt/total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도의 비율 : \", (rare_freq/total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_input_train에는 총 32,037개의 단어가 있네요. 그 아래의 통계 정보들을 해석해볼까요?\n",
    "\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.38%밖에 되지 않아요.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8,233으로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`texts_to_sequences()`는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행합니다. \n",
    "\n",
    "현재 단어 집합의 크기를 8000으로 제한했으니까 이제 8000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75, 224, 697, 52, 229, 2, 68, 3, 3518, 2560, 4, 1056, 620, 4502, 1661, 2455, 2391, 697, 52, 224, 31, 19, 346, 15, 49, 588, 982, 45, 3878, 1930, 66, 101, 129, 27, 44, 17, 80, 603, 3878, 772, 1906, 1777, 193, 907, 46, 147, 115, 118, 43], [599, 338, 15, 3, 272, 1581, 366, 60, 6, 3, 1119, 987, 273, 304, 20, 91, 38, 180], [7, 2643, 1471, 2561, 274, 19, 45, 3, 5, 17]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더이상 텍스트가 아닌 정수가 출력되고 있습니다.\n",
    "\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행하겠습니다. 케라스의 토크나이저를 사용하여 `decoder_input_train`을 입력을로 전체 단어 집합과 각 단어에 대한 빈도수를 계산합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다. 이는 `tar_tokenizer.word_inex`에 저장되어있습니다. `tar_tokenizer.word_counts.items()`에는 단어와 각 단어의 등장 빈도수가 저장되어져있는데, 이를 통해서 통계적인 정보를 얻어서 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10616\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8223\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2393\n",
      "단어 집합에서 희귀 단어의 비율: 77.45855312735493\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.94233791960037\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈소다 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있습니다. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.94%밖에 되지 않습니다. 아까 했던 것과 동일하게 이 단어들은 모두 제거하겠습니다. \n",
    "\n",
    "2393에서 어림잡아 2000을 단어 집합의 크기로 제한하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input!\n",
      "input :  [[1, 3, 25, 35, 30], [1, 181], [1, 154, 23, 383, 441, 38, 12], [1, 3, 21, 9, 6, 82, 5, 375, 348], [1, 5, 1393, 34, 268]]\n",
      "output!\n",
      "ouput :  [[3, 25, 35, 30, 2], [181, 2], [154, 23, 383, 441, 38, 12, 2], [3, 21, 9, 6, 82, 5, 375, 348, 2], [5, 1393, 34, 268, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환 되었는지 확인\n",
    "print(\"input!\")\n",
    "print(\"input : \", decoder_input_train[:5])\n",
    "print(\"output!\")\n",
    "print(\"ouput : \", decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정상적으로 정수 인코딩 작업이 끝났습니다. 현재 `decoder_input_train`과 `decoder_target_train`에는 더이상 숫자 2000이 넘는 숫자들은 존재하지 않습니다. 그런데 다음 작업인 패딩하기로  넘어가기 전에 한가지 점검해야 할 것이 있습니다.\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있습니다. 이 현상은 길이가 상대적으로 길었던 원문(text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(summary)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높겠죠.\n",
    "\n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와보겠습니다. 여기서 주의할 점은 요약문인 `decoder_input`에는 `sostoken` 또는 `decoder_target`에는 `eostoken`이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수와 샘플수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않습니다. 그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 것입니다. 길이가 0이 된 `decoder_input`에는 `sostoken`, `decoder_target`에는 `eostoken`만 남아있을 것입니다.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 `drop_train`과 `drop_test`라는 변수에 저장해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 갯수 :  0\n",
      "삭제할 테스트 데이터의 갯수 :  0\n",
      "---\n",
      "훈련 데이터의 갯수 :  51364\n",
      "훈련 레이블의 갯수 :  51364\n",
      "테스트 데이터의 갯수 :  12835\n",
      "테스트 레이블의 갯수 :  12835\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print(\"삭제할 훈련 데이터의 갯수 : \", len(drop_train))\n",
    "print(\"삭제할 테스트 데이터의 갯수 : \", len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 데이터의 갯수 : \", len(encoder_input_train))\n",
    "print(\"훈련 레이블의 갯수 : \", len(decoder_input_train))\n",
    "print(\"테스트 데이터의 갯수 : \", len(encoder_input_test))\n",
    "print(\"테스트 레이블의 갯수 : \", len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩하기\n",
    "\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬처리 하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 합니다. 아까 정해두었던 최대 길이로 패딩을 해 줄 것입니다. 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계하기\n",
    "\n",
    "이제는 모델을 설계할 시간입니다. 우선 함수형 API를 이용해서 인코더를 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape = (text_max_len, ))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고 hidden state의 크기를 256으로 정의했습니다. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터입니다. 이 파라미터는 LSTM의 용량의 크기나 LSTM의 뉴런 갯수라고 생각하면 됩니다. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아닙니다.\n",
    "\n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였습니다. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있습니다. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "디코더를 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 lstm\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout=0.4, recurrent_dropout = 0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일합니다. 하지만 LSTM의 입력을 정의할 때 `initial_state`의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어주어야 합니다.\n",
    "\n",
    "디코더의 출력층을 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 128)      1024000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 394240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 50, 256), (N 525312      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 128)    256000      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_4[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 2000)   514000      lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 `tar_vocab`의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 합니다. 그렇기 때문에 Dense의 인자로 `tar_vocab`을 주고, 활성화 함수로 소프트맥스 함수를 사용하고 있습니다.\n",
    "\n",
    "지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq입니다. 그런데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있습니다. 바로 위에서 말했던 어텐션 메커니즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "\n",
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야한다는 뜻입니다. 어텐션 함수를 설계하는 것은 다음으로 미루고, 여기서는 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 배워봅시다.\n",
    "\n",
    "아래의 코드를 수행하여 깃허브에 공개되어져있는 어텐션 함수를 다운로드하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 경로에 `attention.py` 파일이 생겼으니 어텐션 메커니즘을 사용할 준비가 되었습니다. 설계한 디코더의 출력층을 아래와 같이 수정하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 128)      1024000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 394240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 50, 256), (N 525312      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 128)    256000      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_4[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_4[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_7[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name = 'attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하과 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련하기\n",
    "\n",
    "설계한 모델을 가지고 훈련을 진행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 196s 977ms/step - loss: 2.7120 - val_loss: 2.4264\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 192s 957ms/step - loss: 2.3861 - val_loss: 2.2877\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 193s 960ms/step - loss: 2.2455 - val_loss: 2.1736\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 193s 962ms/step - loss: 2.1286 - val_loss: 2.0775\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 201s 1s/step - loss: 2.0429 - val_loss: 2.0260\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 200s 997ms/step - loss: 1.9784 - val_loss: 1.9890\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 213s 1s/step - loss: 1.9266 - val_loss: 1.9522\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 216s 1s/step - loss: 1.8814 - val_loss: 1.9305\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 200s 996ms/step - loss: 1.8397 - val_loss: 1.9092\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 207s 1s/step - loss: 1.8037 - val_loss: 1.8935\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 202s 1s/step - loss: 1.7685 - val_loss: 1.8829\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 201s 999ms/step - loss: 1.7369 - val_loss: 1.8684\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 201s 1s/step - loss: 1.7080 - val_loss: 1.8646\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 210s 1s/step - loss: 1.6798 - val_loss: 1.8601\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 230s 1s/step - loss: 1.6529 - val_loss: 1.8583\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 230s 1s/step - loss: 1.6280 - val_loss: 1.8506\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 230s 1s/step - loss: 1.6058 - val_loss: 1.8474\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 202s 1s/step - loss: 1.5827 - val_loss: 1.8474\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 203s 1s/step - loss: 1.5622 - val_loss: 1.8481\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "history = model.fit(\n",
    "    x = [encoder_input_train, decoder_input_train],\n",
    "    y = decoder_target_train,\n",
    "    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "    batch_size = 256,\n",
    "    callbacks = [es],\n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EarlyStopping은 한국어로 해석하면 '조기 종료'라는 뜻을 가지고 있습니다. **특정 조건이 충족되면 훈련을 멈추는 역할**을 합니다. 여기서는 `val_loss`(검증 데이터의 손실)을 모니터링 하면서, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 `parience = 2` 2회 관측되면 학습을 멈추도록 설정되어있습니다. 19번째 epoch쯤에서 조기종료 됩니다.\n",
    "\n",
    "훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1d3H8c9JMtn3TPYEEvYQIAHCjgiCiriB9aHuS1W0dlHbWrV9amu3V1drrVXr9qjVolbADVQWg6CCkISwJpAACSSE7Csh+3n+uAPEkA2YzJbf+/Wa10zmnpn55Tp+OTn3nnOV1hohhBDOz83eBQghhLAOCXQhhHAREuhCCOEiJNCFEMJFSKALIYSL8LDXB5vNZp2QkGCvjxdCCKeUmZlZobUO726b3QI9ISGBjIwMe328EEI4JaVUYU/bZMhFCCFchAS6EEK4CAl0IYRwEXYbQxdCiPPR2tpKUVERTU1N9i5lQHl7exMXF4fJZOr3ayTQhRBOpaioiICAABISElBK2bucAaG1prKykqKiIhITE/v9OhlyEUI4laamJsLCwlw2zAGUUoSFhZ3zXyES6EIIp+PKYX7K+fyOThfoeaX1/OajfTS3tdu7FCGEcChOF+hF1Sd5+YvDbD1UZe9ShBCDUE1NDc8+++w5v27RokXU1NQMQEVnOF2gzxgeho/JnQ05pfYuRQgxCPUU6O3tvY8arFmzhuDg4IEqC3DCQPc2uTN7pJkNOWXI1ZaEELb26KOPcvDgQVJTU5kyZQrz5s3jpptuYvz48QAsXryYyZMnk5yczAsvvHD6dQkJCVRUVFBQUEBSUhL33HMPycnJXHbZZZw8edIqtTnlaYsLkiJYt6+UnJJ6xsYE2rscIYSdPPHhXvYdq7Pqe46NCeSXVyf3uP0Pf/gDe/bsITs7m40bN3LllVeyZ8+e06cXvvLKK4SGhnLy5EmmTJnCt771LcLCwr7xHnl5eSxfvpwXX3yRpUuXsmLFCm655ZYLrt3peugAl4yJRClk2EUIYXdTp079xrniTz/9NCkpKUyfPp2jR4+Sl5d31msSExNJTU0FYPLkyRQUFFilFqfsoYcHeJESF8z63DJ+MH+kvcsRQthJbz1pW/Hz8zv9eOPGjaxfv54tW7bg6+vL3Llzuz2X3MvL6/Rjd3d3qw25OGUPHYxhl51Hayirc+3pv0IIxxIQEEB9fX2322prawkJCcHX15fc3Fy2bt1q09qcN9DHRgLwWW6ZnSsRQgwmYWFhzJo1i3HjxvHwww9/Y9vChQtpa2tjwoQJ/OIXv2D69Ok2rU3Z60yRtLQ0fSEXuNBaM/uP6SRFB/LS7WlWrEwI4chycnJISkqydxk20d3vqpTK1Fp3G3pO20NXSrEgKYIv8stpapVZo0II4bSBDjA/KZKm1g6+zK+wdylCCGF3Th3o04aF4u/lwfocGUcXQginDnQvD3fmjDLzWW4pHR0ya1QIMbg5daADzB8TSWldM3uO1dq7FCGEsCunD/R5YyJwU8iwixBi0HP6QA/182Ty0BBZBkAIYRPnu3wuwFNPPUVjY6OVKzqjz0BXSsUrpdKVUjlKqb1KqQd6aDdXKZVtafO59Uvt2fykSPYeq6Ok1jrTZ4UQoieOHOj9WculDfix1jpLKRUAZCql1mmt951qoJQKBp4FFmqtjyilIgao3m4tSIrgDx/nsj6njFunD7XlRwshBpnOy+deeumlRERE8M4779Dc3MySJUt44oknOHHiBEuXLqWoqIj29nZ+8YtfUFpayrFjx5g3bx5ms5n09HSr19ZnoGutS4ASy+N6pVQOEAvs69TsJmCl1vqIpZ1NB7SHh/szNMyXDTmlEuhCDCYfPwrHd1v3PaPGwxV/6HFz5+Vz165dy7vvvsu2bdvQWnPNNdewadMmysvLiYmJYfXq1YCxxktQUBBPPvkk6enpmM1m69ZscU5j6EqpBGAi8HWXTaOAEKXURqVUplLqth5ev0wplaGUyigvLz+fenuqiwVJkXx1sJLGljarva8QQvRm7dq1rF27lokTJzJp0iRyc3PJy8tj/PjxrF+/nkceeYTNmzcTFBRkk3r6vXyuUsofWAE8qLXuuqK8BzAZmA/4AFuUUlu11gc6N9JavwC8AMZaLhdSeFfzkyJ4+YvDbM6r4PLkKGu+tRDCUfXSk7YFrTWPPfYY995771nbMjMzWbNmDY899hiXXXYZjz/++IDX068eulLKhBHmb2qtV3bTpAj4RGt9QmtdAWwCUqxXZt+mJIQS4O3B+n1ytosQYuB0Xj738ssv55VXXqGhoQGA4uJiysrKOHbsGL6+vtxyyy385Cc/ISsr66zXDoQ+e+hKKQW8DORorZ/sodn7wDNKKQ/AE5gG/M1qVfaDyd2NuaMjSN9fRkeHxs1N2fLjhRCDROflc6+44gpuuukmZsyYAYC/vz9vvPEG+fn5PPzww7i5uWEymXjuuecAWLZsGVdccQXR0dEDclC0z+VzlVKzgc3AbqDD8vTPgCEAWuvnLe0eBu60tHlJa/1Ub+97ocvnduf97GIeeCublffPZNKQEKu+txDCMcjyuT0vn9ufs1y+APrs7mqt/wz8uZ91Doi5oyJwd1Os31cqgS6EGHScfqZoZ0G+JqYkhLBBlgEQQgxCLhXoAAuSItlfWs/RqoGbjSWEsC97XWnNls7nd3S5QJ+fZFxrVNZ2EcI1eXt7U1lZ6dKhrrWmsrISb2/vc3pdv89DdxaJZj+Gh/uxPqeMO2Yl2rscIYSVxcXFUVRUhDUnJzoib29v4uLizuk1LhfoYAy7vPLlYeqbWgnwNtm7HCGEFZlMJhITpbPWHZcbcgFYMDaS1nbNpgNyrVEhxODhkoE+aUgIIb4mGUcXQgwqLhno7m6KeaMj+Gx/GW3tHX2/QAghXIBLBjoYZ7vUNLaSdaTG3qUIIYRNuGygzxllxuSuZNhFCDFouGygB3ibmD4sjHUS6EKIQcJlAx1g/pgIDpWf4HDFCXuXIoQQA861A11mjQohBhGXDvT4UF/GRAWwXgJdCDEIuHSgg3Fpuu0F1dQ2ttq7FCGEGFCDINAjae/QbDwgS+oKIVybywd6alwwZn9P1ssa6UIIF+fyge7mprhkTAQb95fRKrNGhRAuzOUDHYxhl/qmNrYfrrJ3KUIIMWAGRaBfNNKMp4ebDLsIIVzaoAh0X08PZg4PY0NuqUtf5UQIMbgNikAH46IXhZWN5Jc12LsUIYQYEIMm0OcnRQDIsIsQwmU5X6A31cIXf4OOcztjJTrIh+SYQFkGQAjhspwv0HPXwPpfwdZ/nvNLFyRFknWkmsqGZuvXJYQQduZ8gZ5yA4y5CtY/ASW7zumlC5Ii6dCQvt+1rxYuhBic+gx0pVS8UipdKZWjlNqrlHqgl7ZTlFLtSqnrrVvmNz4Ern4afMNgxd3Q0tjvl46LDSQy0EuGXYQQLqk/PfQ24Mda6yRgOvA9pdTYro2UUu7AH4FPrVtiN/zCYPGzULEf1j3e75cppbhkTCSbDpTT3NY+gAUKIYTt9RnoWusSrXWW5XE9kAPEdtP0B8AKwDankYyYD9O/B9tfhANr+/2yS8dGcKKlna2HZNaoEMK1nNMYulIqAZgIfN3l+VhgCfB8H69fppTKUEpllJdbYRx7/uMQkQzv3w8N/Xu/mcPNeJvcZNhFCOFy+h3oSil/jB74g1rrui6bnwIe0Vr3Oo6htX5Ba52mtU4LDw8/92q7MnnDt16Cpjp4/3vQj1mg3iZ3Zo8IZ0NOmcwaFUK4lH4FulLKhBHmb2qtV3bTJA14SylVAFwPPKuUWmy1KnsTORYu/TXkfQrbX+rXS66aEE1xzUne/PrIABcnhBC205+zXBTwMpCjtX6yuzZa60StdYLWOgF4F7hfa/2eVSvtzbR7YcQCWPu/UL6/z+bXpMQwe4SZ363O4VC5LAUghHAN/emhzwJuBS5RSmVbbouUUvcppe4b4Pr6Rym49lnw9IMVd0Fb7xOH3NwUf/mfFDw93Hjo7WxZJ10I4RL6c5bLF1prpbWeoLVOtdzWaK2f11qfdRBUa32H1vrdgSm3FwGRcM0zcHw3fPbbPptHBXnz+yXj2VlUyz8+y7dBgUIIMbCcb6Zob8YsgrTvwFf/gEOf99n8ygnRXDcxln+m55N1pNoGBQohxMBxrUAHuOx3EDYCVt0HjX2fa/6ra5OJCvTmobezOdHcZoMChRBiYLheoHv6GqcyniiHDx/o81TGQG8TTy5N4UhVI79dvc9GRQohhPW5XqADxKTCJT+HnA8g+80+m08bFsayOcNYvu0o6/bJhCMhhHNyzUAHmPlDSLgIPn4EKg/22fxHl44iKTqQR1fsorxeltcVQjgf1w10N3dY8rxxv3IZtLf22tzLw52/35BKfXMbj67YJbNIhRBOx3UDHSAoDq56CoozYNOf+2w+KjKARxaOYUNuGcu3HbVBgUIIYT2uHegA466DlJuMQD+ytc/md85MYNaIMH7z0T4OV5ywQYFCCGEdrh/oAFf8EYLiYeU9xkJevTg1i9TkrnhQZpEKIZzI4Ah070DjVMbaYljzcJ/No4N8+P1149l5tIZnZBapEMJJDI5AB4ifCnMehl1vwe6+Vya4akIMSybG8kx6PjtkFqkQwgkMnkAHI9DjpsBHP4Kavg96PiGzSIUQTmRwBbq7B1z3Iuh2WHUvtPce0oHeJv66NIXCqkZ+uzrHRkUKIcT5GVyBDhCaCFf+FQq/hI8f7nNpgOnDwlh20TCWbzvCeplFKoRwYIMv0AFSboBZD0DGK7DlmT6b/+gyyyzSlbuoaJBZpEIIxzQ4Ax1g/q9g7LWw9hew7/1em3p5uPPUt1Opa5JZpEIIxzV4A93NDZb8C+LSjKUBijJ6bT46KoCfXj6a9TllvLVdZpEKIRzP4A10AJMP3LAc/CNh+Q1QXdBr8+/MSjw9i7RAZpEKIRzM4A50AP9wuPldaG+BN5fCyZ7POT81i9TDzZhF2iazSIUQDkQCHSB8FHz7Tag6BO/cBm0tPTaNDvLht0vGk320hn+m970srxBC2IoE+imJF8E1/4DDm+CjB3s9nfGalBgWp8bw9w0H2Li/zIZFCiFEzyTQO0u9ES5+xLjK0ea/9Nr0d0vGMyYqkB/8Zwd5pfU2KlAIIXomgd7V3Mdgwrfhs9/2uuaLn5cHL9+RhrenO995bTuVcn66EMLOJNC7UsoYehk6C977LhR+1WPT6CAfXrotjbK6Zu79dybNbe02LFQIIb5JAr07Hl7w7TcgeAi8dVOv1yRNiQ/mr0tTyCis5rGVu2XSkRDCbvoMdKVUvFIqXSmVo5Taq5R6oJs2NyuldlluXymlUgamXBvyDYWb/wvKDd68Hk5U9tj0qgkxPLRgFCuzinnucznzRQhhH/3pobcBP9ZaJwHTge8ppcZ2aXMYuFhrPQH4DfCCdcu0k9BhxsSj2mKjp97a1GPTH84fwTUpMfzpk/18sqfEhkUKIYShz0DXWpdorbMsj+uBHCC2S5uvtNanZuRsBeKsXajdDJkGS56Ho1vh/fuho/vJREop/nT9BCYOCeaht3eyp7jWxoUKIQa7cxpDV0olABOBr3tpdhfwcQ+vX6aUylBKZZSXl5/LR9vXuOtg/i9hzwpI/12PzbxN7rxwaxqhfp7c9dp2Sut67tELIYS19TvQlVL+wArgQa11t1daVkrNwwj0R7rbrrV+QWudprVOCw8PP5967Wf2QzDxVuP89Kx/99gsPMCLl25Po6Gpjbtfy+Bki5z5IoSwjX4FulLKhBHmb2qtV/bQZgLwEnCt1rrnI4jOSim46m8wbJ4xk/TQxh6bJkUH8vSNE9lzrJYfvZNNR4ec+SKEGHj9OctFAS8DOVrrJ3toMwRYCdyqtT5g3RIdiLsJlr4GYSPh7dugLLfHpvOTIvn5oiQ+3nOcJ9e57i4RQjiO/vTQZwG3ApcopbItt0VKqfuUUvdZ2jwOhAHPWrb3vri4M/MOgpvfAZO3cTpjL0vu3jU7kRumxPNMej6rdhTZrkYhxKCk7DURJi0tTWdkOHHuH8uG168FT3+4/QMIG95ts5a2Dm575WuyCmv4zz3TSEsItXGhQghXopTK1FqndbdNZoqer5hUuP1DaG2EV6+Eirxum3l6uPH8LZOJCfbm3n9ncrSq0caFCiEGCwn0CxE9Ae74CNpbjVDvYUw92NeTl++YQmt7B3e9tp36plYbFyqEGAwk0C9UZDLcsdp4/OqVULq322bDw/157pbJHCw/wQ+W75CrHQkhrE4C3RoixsAda8DdE169Ckp2dtts1ggzv742mY37y/ndmhwbFymEcHUS6NZiHgF3rgZPP3jtaijO7LbZzdOGcuesBP7vywLe/LrQxkUKIVyZBLo1hQ4zhl+8g+D1xXB0W7fN/vfKscwbHc7j7+/ly/wKGxcphHBVEujWFjIU7vwYfMPg30ugcMtZTdzdFE/fOJER4f4sez2DdLkuqRDCCiTQB0JQHNy5BgKi4Y1vweHNZzUJ8Dbx+l1TGRrmx92vZfCfr4/YoVAhhCuRQB8ogTHG8EtwPLz5P3Aw/awmkYHevHPfDGaPMPOzVbv54ye5su6LEOK8SaAPpIBII9TDhsN/vg15689q4u/lwcu3p3Hj1CE8t/EgD7ydLdcmFUKcFwn0geZnNmaUho+Gt26E/WcvFe/h7sbvl4zjpwtH8+HOY9z60jZqGlvsUKwQwplJoNuCb6ix3kvkOHj7Ftj3wVlNlFLcP3cET984keyjNVz33FccqZRlAoQQ/SeBbis+IXDbexAzCf57B+zpdll5rkmJ4Y27p1HZ0MKSZ78k+2iNbesUQjgtCXRb8g6CW1dC/FRYcRfseqfbZlMTQ1l5/0x8vdy54YUtfLr3uI0LFUI4Iwl0W/MKgFtWwNBZsHIZbH8ZulnCeHi4P6vun8XoqEDueyOTV744bIdihRDORALdHjz94KZ3YPg8WP0jeGEu5K8/K9jN/l68dc90Lk2K5Ncf7eOJD/fSLqc1CiF6IIFuL56+cPO7sPh5OFllTEB69cqzZpb6eLrz3C2TT6//cv+bmXLhaSFEtyTQ7cnNHVJvhO9nwqK/QGU+/N9CeOP6b6zY6O6m+OXVyTx+1VjW7ivlxhe3UtHQbMfChRCOSALdEXh4wtR74IfZsOAJKNoO/5oD79wO5WcuMP2d2Yk8f8tkco/Xcd2zX3GwvMGORQshHI0EuiPx9IXZD8KDu2DOTyFvHTw7Dd77HtQYa71cnhzF8numc6K5jW899xXbDlfZuWghhKOQQHdE3kFwyc/hgZ0w7buw+7/wj8mw5qfQUMbEISGsun8WoX6e3PLS16zMKsJeF/sWQjgOZa8gSEtL0xkZGXb5bKdTWwSf/wl2vAEeXjDtPpj1Q2q0H8v+ncm2w1VcnhzJbxaPIyLA297VCiEGkFIqU2ud1u02CXQnUnkQ0n8Pe94FryCY9UPapizjpW3lPLnuAD4mdx6/aizXTYpFKWXvaoUQA6C3QJchF2cSNhyufxnu+wKGzoTPfoPHM5O4z/1D1t49mhER/vz4vzu589XtHKs5ae9qhRA2Jj10Z3Z0G2z4NRRsBuWOHrGAdJ9LeXBHFB1unvxsURI3To2X3roQLuSChlyUUvHA60AU0AG8oLX+e5c2Cvg7sAhoBO7QWmf19r4S6FZUvh+y/wM734KG47R7h7DOfQ7/qJpKUOJk/vCtFIaE+dq7SiGEFVxooEcD0VrrLKVUAJAJLNZa7+vUZhHwA4xAnwb8XWs9rbf3lUAfAO1tcGgjZL+Jzl2Nam/mgB7CSn0xCXPvYOncybi5SW9dCGdm1YOiSqn3gWe01us6PfcvYKPWernl5/3AXK11SU/vI4E+wE5Ww54VtGS8gWfpDlq1O9neU4i/5G6iJl9rTGYSQjgdqx0UVUolABOBr7tsigWOdvq5yPKcsBefEJhyN57f3Yi+fyuHRt7O0Ob9RH18Nyf/OJKONT/9xvICQgjn1+9AV0r5AyuAB7XWdV03d/OSs7r+SqllSqkMpVRGeXn5uVUqzpuKSGL0LX+Dh/bwdNTv2dA0hvZtLxvLCzw3G7Y8Cw3y30MIZ9evIRellAn4CPhUa/1kN9tlyMVJaK1ZvbuEv763lTmtm/lu0NdENewFNw8YeTmk3gQjL5MhGSEcVG9DLh79eLECXgZyugtziw+A7yul3sI4KFrbW5gL+1FKcdWEGGYMu5InPkxk+s4FXBZezW8SdhN5eBXsXw2+YTD+f4xwj5oActqjEE6hP2e5zAY2A7sxTlsE+BkwBEBr/bwl9J8BFmKctnin1rrX7rf00B3Dun2l/HzVbsrqm1k0Npz/TSohpmAV5K6G9hbjwtapN8H4peAfbu9yhRj0ZOq/6FVDcxsvbT7ES5sP09jSxnWT4nhotpnYoo+N89uLM40hmRGXGuE+aqEMyQhhJxLool+qTrTwbHo+r28tBA03TRvC9y8ZgflkwTcmLuETemZIJjpFhmSEsCEJdHFOjtWc5OkNefw3swgvDzfump3IPXOGEWhSpycuGUMyzRCRbAT7hKXgH2Hv0oVweRLo4rwcKm/gr+sOsHpXCcG+Jr578XBun5mAt8ndMnFpJexcblxhSblD3BSInwJxU43HgdH2/hWEcDkS6OKC7Cmu5c+f7ufzA+VEBnrxw/kjWZoWj8ndMo2h/IAR7AVfQEm2cTAVIDDOEvCWkI+eYKznLoQ4bxLowiq+PlTJnz7dT2ZhNQlhvjx06SiunhDzzfVh2prh+G5jJcii7VCUAbXG5fNw9zTG3OOmQFyaEfJBcTIGL8Q5kEAXVqO1Jn1/GX/6ZD+5x+tJig7k4ctHMW90RM/L9NaVQHGGJeQz4NgOaLOs1+4f1akXPwWiU41rqwohuiWBLqyuo0Pz4a5jPLnuAIWVjaQNDeGhS0cxc3hY3+uvt7dC6R4j3E/15KsPG9vcPCAy+UzAx6YZF/aQXrwQgAS6GECt7R28k3GUpzfkUVrXzLjYQJbNGc6icVF4uJ/D2m8N5UawF2cYQV+cBS31xjafECPY4yy32MnGc0IMQhLoYsA1tbbz3o5iXth0iEMVJ4gL8eHu2YksnRKPr2efK0ycraPduHBHccaZsfiyHE6v+RY2stNYfJpx+qT7eXyOEE5GAl3YTEeHZl1OKS9sOkRmYTXBviZumz6U22YmYPa/wDNcmuqM8fdTAV+0HRorjG0mX2P8PS7NWK7APBLMo8DL/8J/KSEciAS6sIuMgir+tekQ6/aV4uXhxvWT47jnomEkmP2s8wFaQ03hmXAvyjDWeO9oPdMmMA7CRxnhbh4F4aPBPBr8zDIuL5ySBLqwq/yyBl7afIiVWcW0dnSwMDmKZXOGMXHIAIyDt7VA1SGoOAAV+41z5Cv2Q0UetDaeaecTcnbIm0dC8FBwO6frvghhUxLowiGU1TXx6lcFvLG1kLqmNqYmhnLvnGHMGx0x8Nc67eiAuuKzQ758/5lhGwAPb2N8PigOAmOM2a6BscbjgBjjXoZxhB1JoAuH0tDcxlvbjvDKF4c5VtvEyAh/7pkzjGtTY/DycLd9QY1VRrBXHLDc8ozwrys2ljjoyivQEvCdwv5U8J96zjdUhnTEgJBAFw6ptb2Dj3Yd41+fHyL3eD2RgV7cNiOBG6bEE3ahB1CtpfUk1B0zbvUllqC33NeXGM83lILu+ObrPLwhJNE4hz5shOVmeewXLmEvzpsEunBoWms25VXw4qZDfJFfgaeHG1dPiOGOmQmMjwuyd3l9a28zQv104B+D2iJjLL/yoHHf+UCtV+CZcA8d3insh4O3E/y+wq4k0IXTyCut57UtBazMKqaxpZ2JQ4K5Y2YCV4yLxtPDSQ9WtrdB7VEj3CvzocpyX5kPNUf5xvXU/SLOhHtIAngGgMnHOC3T5AMm706PLfcePpaffcDNDkNWwqYk0IXTqWtq5d2MIl7fUkBBZSPhAV7cNHUIN08bQkSgt73Ls57WJqguOBPwlfmWnn2+0es/V+5eZ4e+p9+Ze09/Y62cU4+7e97kZ3nOcjP5gJsJ3E2g3GS4yM4k0IXT6ujQbMor57WvCkjfX46Hm+KK8dHcMXMok4aE9L1ujDNrbTJOtWw9abk1Qlvn5zpv66FNSyO0njDuW05AS4Nx39r4zdM4z8WpcHczGX8RnHrs7mGsxXPWY5Pxj4JvmOUW2ulxp5tPqMz27QcJdOESCipO8O+thbyTcZT6pjbGxQZy+4wErk6JMS66Ic5NR7sR6i2NZ4K+5YTlH4BOt9aTxjGA9jboaLM8brU8bjvz+PRzp9qeer7NeM/GKuN2ao2e7ngHdRP2oeBrBu9A42Dz6ZuXZcjJyxh28vAynjd1euyCQ1AS6MKlnGhuY9WOYl77qoC8sgZCfE3cMHUIt0wfSmywj73LE31pa7aEe2WXW0/PVRh/dZwPN5Ml5L2tE/BaA9o47KE7ztzQnX7WZ+6/8XynbbN+CPMfP68SJNCFS9Jas+VgJa9tKWDdPmO8+bKxUXx7ajwXjTCf22qPwrG1NEJznWU4qcm4P31rNv6KaGs21tnv7udTr9PtVihGWY4lWI4nqE4/n7Xt1PN0et4NEmbBiAXn9+m9BLoMWAmnpZRi5ggzM0eYKapu5I2tR3h7+xE+2Xscs78X16bGcN2kWMZGB7r2WPtg4OkrFz7pB+mhC5fS0tZB+v4yVmYV8VluGa3tmtGRAVw3KZZrU2OJCnKhM2TEoCRDLmJQqj7Rwke7S1iVVUTWkRqUgtkjzCyZGMvlyVH4eckfqML5SKCLQe9wxQlW7Shm1Y4ijladxNfTnYXJUVw3KY4Zw8NwH+jFwYSwkgsKdKXUK8BVQJnWelw324OAN4AhGGPyf9Fa/19fRUmgC3vQWpNRWM3KrCI+2lVCfVMbkYFeLJ4Yy3UT4xgdFWDvEoXo1YUG+hygAXi9h0D/GRCktX5EKRUO7AeitNYtvb2vBLqwt6bWdjbkGOPtnx8op61DkxwTyJKJsVyTGkNEgIy3C8dzQWe5aK03KaUSemsCBCjjNAJ/oApoO486hbApb5M7V06I5soJ0VQ0NPPhzmOs2lHMb1fn8Ps1OVzoklsAAA2aSURBVMyS8XbhZPo1hm4J9I966KEHAB8AY4AA4Nta69U9vM8yYBnAkCFDJhcWFp534UIMlPyyet7bcYz3sospqj6Jj8mdS8dGsmRiLLNHmjHJ+e3Cji74oGgfgX49MAv4ETAcWAekaK3rentPGXIRjk5rTWZhNat2FLN6dwk1ja2E+nly9YRoFk+MJTU+WM5vFzY30BOL7gT+oI1/GfKVUocxeuvbrPDeQtiNUoq0hFDSEkL55dXJfH6gnPd2FLN8+1Fe21LI0DBfFqfGsnhiLInWuvC1EBfAGoF+BJgPbFZKRQKjgUNWeF8hHIanhxuXjo3k0rGR1DW18sme47y3o5inP8vj7xvySIkPZklqDFelxGB2lKstiUGnP2e5LAfmAmagFPglYALQWj+vlIoBXgWiAYXRW3+jrw+WIRfhCo7XNvHBzmLe23GMfSV1uLspLhppZnFqLPOTIgjwNtm7ROFiZGKREDaw/3g972UX80H2MYprTuLp7sZFI81cPi6KS5MiCfHztHeJwgVIoAthQx0dmswj1Xyy5zif7DlOcc1J3N0U04eFsjA5isuTo1zrqkvCpiTQhbATrTV7iuv4ZG8JH+85zqHyEygFk4aEcMU4I9zjQ2UVQdF/EuhCOACtNfllDXxs6bnvKzHO7E2OCeSKcVEsHBfFiAhZekD0TgJdCAdUWHmCT/ca4Z51pAaAERH+LEw2wj05RtZxF2eTQBfCwR2vbWLtPiPctx6qpENDXIgP88dEMG9MBNOHhcl1UwUggS6EU6k60cL6faV8uvc4Xx6soKm1Ax+TO7NGhHHJmEjmjQknOkiunTpYSaAL4aSaWtvZcqiS9NwyPssto6j6JABJ0YFcMiacS8ZEkBofIuu5DyIS6EK4gFMHVT/LLWNDbhmZhdW0d2hCfE1cPCqceWMiuHhUOMG+cr67K5NAF8IF1Ta2simvnPTcMjYeKKfqRAtuCiYPDWHemAguGRPB6MgAObDqYiTQhXBx7R2anUU1p4dm9h4zTomMDfbh4tHhzB0VzqwRZlnX3QVIoAsxyByvbSJ9fxnpuWV8mV/BiZZ2PN3dmJIYwrzREcwdHc7wcH/pvTshCXQhBrGWtg4yCqrYeMAYnskrawCM3vu8MeHMHRXBzBFh+HpK790ZSKALIU4rqm7k8wPlpOeW89XBChotvfdpw0K5eFQ4c0dHMDzcT3rvDkoCXQjRrea2djIKqk8fWM239N7jQ32YO8oYmpkxXHrvjkQCXQjRL0erGtl4oJzP95fxZX4lJ1vPjL1fNDKci0aaSYoKxE3Oe7cbCXQhxDlrbmtn2+EqPt9fzhf5FeQerwfA7O/FRSPNXDTSzOyRZiICZClgWxroa4oKIVyQl4e7pVceDkBpXROb8yrYnFfOpgPlrNpRDMCYqADmjDJ671MSQmXNGTuSHroQ4px1dGj2ldSdDviMgmpa2jvw8nBjaqJxcPWikeGMipRTI61NhlyEEAOqsaWNrw9XsfmAEfCnTo2MCPA6PfY+Y3gYkXKlpgsmQy5CiAHl6+nBvNERzBsdAcCxmpN8kVfBprxyNuSWsiKrCIBEsx/Th4UxY3gY04eFyvi7lUkPXQgxoNo7NDkldWw9VMmWg5VsO1xFfXMbAMPD/ZgxPIwZw8xMHxZKmL+Xnat1fDLkIoRwGG3tHewrqWPLwUq2HKpk++EqTrS0AzAq0p8Zlh78tMQwQvxk5ciuJNCFEA6rtb2D3cW1p3vwGQXVnGw1An5MVIClBx/G1MRQWRoYCXQhhBNpaetgd3HN6R58RkE1zW0dgHHN1UlDgpk8NITJQ0MYZvYfdJOcJNCFEE6rua2d7CM1ZBRWk1VYTeaRamoaWwEI9PZg0tAQJg8xAj4lPtjllwi+oLNclFKvAFcBZVrrcT20mQs8BZiACq31xedfrhBCnOHl4c60YWFMGxYGGFduOlRxgqzCarKOVJNZWM3nB8rRGtwUjIkKZPLQECYNDWbykFDiQ30GzbnwffbQlVJzgAbg9e4CXSkVDHwFLNRaH1FKRWity/r6YOmhCyGspfZkK9lHa8gsrGbHkWp2HKmhwXImjdnf6/QwTVpCCONig/DycN7ZrBfUQ9dab1JKJfTS5CZgpdb6iKV9n2EuhBDWFORjXFf14lHGMgXtHZoDpfVkWnrxWYXVrN1XCoCnhxupccFMSQwhLSGUyUNDCPQ22bN8q+nXGLol0D/qoYd+aqglGQgA/q61fr2H91kGLAMYMmTI5MLCwvMuXAghzkVFQzOZhdVsP1zF9sJq9hbX0tahUZZhmqkJRsBPSQglKshxJzxd8EHRPgL9GSANmA/4AFuAK7XWB3p7TxlyEULYU2NLG9lHatheUM32giqyjlTTaDkfPj7UhylDQ5mSGMqUhBCHulzfQE/9L8I4EHoCOKGU2gSkAL0GuhBC2JOvpwczR5iZOcIMnJnwtL3A6MVvyitnpWVFyRBfk6X3HsKkISEkxwTh4+l44/DWCPT3gWeUUh6AJzAN+JsV3lcIIWzGw92NCXHBTIgL5q7ZiWitKahsNIZoCozbOss4vLubYmSEPylxwUyIDyIlLpjRUQGY3N3s+zv01UAptRyYC5iVUkXALzHGzNFaP6+1zlFKfQLsAjqAl7TWewauZCGEGHhKKRLNfiSa/Vg6JR6Asvomdh6tZVdRDTuLavl033HezjgKgJeHG2NjAo2QjwtiQlwww8x+Np34JBOLhBDiPGmtOVLVyM6iWnYdrWFXUS17jtWeHosP8PJgvCXcU+KCmBAfTEyQ9wWNx8vyuUIIMQCUUgwN82NomB/XpMQAximT+WUN7CyqMXryR2t5+YtDtLYbnWezvyf3XTycuy8aZvV6JNCFEMKK3N0Uo6MCGB0VwNI0Y6imua2dnJL60wEfHjAwywRLoAshxADz8nAnNT6Y1PhgmDFwn2PfQ7JCCCGsRgJdCCFchAS6EEK4CAl0IYRwERLoQgjhIiTQhRDCRUigCyGEi5BAF0IIF2G3tVyUUuXA+V7hwgxUWLGcgeQstUqd1ucstUqd1jXQdQ7VWod3t8FugX4hlFIZPS1O42icpVap0/qcpVap07rsWacMuQghhIuQQBdCCBfhrIH+gr0LOAfOUqvUaX3OUqvUaV12q9Mpx9CFEEKczVl76EIIIbqQQBdCCBfh0IGulFqolNqvlMpXSj3azXallHrasn2XUmqSHWqMV0qlK6VylFJ7lVIPdNNmrlKqVimVbbk9bus6O9VSoJTabanjrIu6Osg+Hd1pX2UrpeqUUg92aWOXfaqUekUpVaaU2tPpuVCl1DqlVJ7lPqSH1/b6fbZRrX9WSuVa/tuuUkoF9/DaXr8nNqjzV0qp4k7/fRf18Fqb7dMe6ny7U40FSqnsHl5rm/2ptXbIG+AOHASGAZ7ATmBslzaLgI8BBUwHvrZDndHAJMvjAOBAN3XOBT6y9z611FIAmHvZbvd92s334DjGZAq771NgDjAJ2NPpuT8Bj1oePwr8sYffo9fvs41qvQzwsDz+Y3e19ud7YoM6fwX8pB/fDZvt0+7q7LL9r8Dj9tyfjtxDnwrka60Paa1bgLeAa7u0uRZ4XRu2AsFKqWhbFqm1LtFaZ1ke1wM5QKwta7Ayu+/TLuYDB7XW5zur2Kq01puAqi5PXwu8Znn8GrC4m5f25/tsVd3VqrVeq7Vus/y4FYgbyBr6o4d92h823ae91amUUsBSYPlAfX5/OHKgxwJHO/1cxNlB2Z82NqOUSgAmAl93s3mGUmqnUupjpVSyTQv7Jg2sVUplKqWWdbPdofYpcAM9/0/iKPs0UmtdAsY/8EBEN20cbb8CfAfjr7Hu9PU9sYXvW4aGXulhGMuR9ulFQKnWOq+H7TbZn44c6Kqb57qeY9mfNjahlPIHVgAPaq3rumzOwhgySAH+Abxn6/o6maW1ngRcAXxPKTWny3ZH2qeewDXAf7vZ7Ej7tD8cZr8CKKV+DrQBb/bQpK/vyUB7DhgOpAIlGMMZXTnSPr2R3nvnNtmfjhzoRUB8p5/jgGPn0WbAKaVMGGH+ptZ6ZdftWus6rXWD5fEawKSUMtu4zFO1HLPclwGrMP5s7cwh9qnFFUCW1rq06wZH2qdA6alhKct9WTdtHGa/KqVuB64CbtaWAd6u+vE9GVBa61KtdbvWugN4sYfPd4h9qpTyAK4D3u6pja32pyMH+nZgpFIq0dJTuwH4oEubD4DbLGdmTAdqT/3payuWsbOXgRyt9ZM9tImytEMpNRVjv1farsrTdfgppQJOPcY4QLanSzO779NOeuz1OMo+tfgAuN3y+Hbg/W7a9Of7POCUUguBR4BrtNaNPbTpz/dkQHU5brOkh893iH0KLABytdZF3W206f4c6KOuF3LDOOPiAMaR7J9bnrsPuM/yWAH/tGzfDaTZocbZGH/m7QKyLbdFXer8PrAX4yj8VmCmnfbnMEsNOy31OOQ+tdThixHQQZ2es/s+xfgHpgRoxegh3gWEARuAPMt9qKVtDLCmt++zHWrNxxh3PvVdfb5rrT19T2xc578t379dGCEdbe992l2dludfPfW97NTWLvtTpv4LIYSLcOQhFyGEEOdAAl0IIVyEBLoQQrgICXQhhHAREuhCCOEiJNCFEMJFSKALIYSL+H8szKbjREfKDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'train')\n",
    "plt.plot(history.history['val_loss'], label = 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기\n",
    "\n",
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개 사전을 아래와 같이 미리 준비해둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 합니다.\n",
    "\n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.\n",
    "\n",
    "그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape = (hidden_size, ))\n",
    "decoder_state_input_c = Input(shape = (hidden_size, ))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(Initial state)를 이전 시점의 상태로 사용. \n",
    "# 이는 뒤의 함수 decode_sequence()에서 구현합니다.\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셸 상태인 state_h와 state_c를 버리지 않습니다.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 매커니즘을 사용하는 출력층을 설계해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape = (text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != 'eostoken':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "        \n",
    "        # <EOS>에 도달하거나 최대 길이를 넘으면 중단\n",
    "        if sampled_token == 'eostoken' or len(decoded_sentence.split()) >= summary_max_len - 1:\n",
    "            stop_condition = True\n",
    "        \n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros([1, 1])\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # 상태 업데이트\n",
    "        e_h, e_c = h, c\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트하기\n",
    "\n",
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 확인하는 것이 좋습니다. 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어보겠습니다. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외시키고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력해서 제외시키도록 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            temp = temp + src_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = \"\"\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']:\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  great heavy chewer long lasting dogs love second one purchased seems one come \n",
      "실제 요약 :  big chewer loves it \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  excellent yummy everyone one loved quick shipping product arrived fine condition makes terrific gift \n",
      "실제 요약 :  excellent product \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  great gum chew hours still tastes great bad widely available used \n",
      "실제 요약 :  minty sweet twist rocks \n",
      "예측 요약 :   great gum\n",
      "\n",
      "\n",
      "원문 :  first discovered pasta nyc restaurant first time pasta gluten free diet tried mom dish someone knows real thing tastes like absolutely amazed pasta gluten free actually preferred regular pasta give heavy feeling eating great basically recipe eating gluten free order case skip gluten free pastas try promise amazed \n",
      "실제 요약 :  best gluten free pasta period \n",
      "예측 요약 :   great pasta\n",
      "\n",
      "\n",
      "원문 :  dogs bark every morning get greenie treat addicted dogs bit pricey order amazon keep addiction use two different sizes greenies teenie size good want one give size larger get away one treat per day know put dogs crazy \n",
      "실제 요약 :  best treat in the world \n",
      "예측 요약 :   greenies are great\n",
      "\n",
      "\n",
      "원문 :  like hint sweet peanut butter right organic yummy without stir \n",
      "실제 요약 :  the best peanut butter \n",
      "예측 요약 :   yummy\n",
      "\n",
      "\n",
      "원문 :  lightly sprinkle spice seasoning pork beef chicken ground meats burgers always many years mixture well balanced needs extra seasoning add even use fish great results like seasoning power flavor meat fish apply try season anything want true flavors dominate seasoning well rosemary \n",
      "실제 요약 :  excellent dry spice \n",
      "예측 요약 :   great seasoning\n",
      "\n",
      "\n",
      "원문 :  cannot beat amazons prices best price could find comparing health food stores everywhere else seeds great smoothies \n",
      "실제 요약 :  great deal \n",
      "예측 요약 :   great buy\n",
      "\n",
      "\n",
      "원문 :  sure picked packet made quick something take games night party let sit overnight frig rolled smoked paprika wonderful pretty spicy though like \n",
      "실제 요약 :  fantastic and spicy \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  cats one like foster cats come running night litter boxes know treat time real convenience box temptations delivered door especially winter snow ground \n",
      "실제 요약 :  treats \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  great coffee full bodied touch vanilla flavor nice frothy unlike brands froth lasts longer \n",
      "실제 요약 :  great coffee \n",
      "예측 요약 :   great coffee\n",
      "\n",
      "\n",
      "원문 :  made nights ago ate days brand delicious searched high low find recipe good better bought mine local walmart used imitation crab lobster meat oz says adding egg optional think egg makes better \n",
      "실제 요약 :  delicious \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  know tremendous differences quality tea particular peppermint tea effective ever used calms stomach fast great \n",
      "실제 요약 :  great tea \n",
      "예측 요약 :   great tea\n",
      "\n",
      "\n",
      "원문 :  delicious aroma good quality one best choices coffee delivered fast buy try also vanilla aroma \n",
      "실제 요약 :  delicious aroma \n",
      "예측 요약 :   great coffee\n",
      "\n",
      "\n",
      "원문 :  hesitant order shipping fault gave reason however box dented terrible shape bags sealed perfect condition amazon prompt offer excellent service gave free shipping gave estimated time arrival items received two days week early great job \n",
      "실제 요약 :  item arrived in perfect condition and was great \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  comparison larger softer even bit juicy usually buy major generic brand dried cranberries carried local grocery organic dried cranberries ever cannot say best organic category taste much better non organic brand local grocer buy \n",
      "실제 요약 :  best dried have ever had \n",
      "예측 요약 :   good stuff\n",
      "\n",
      "\n",
      "원문 :  yummy mild delicious new favorite mild coffees called fuel taste like oil truly medium roast pleasant morning makes glad good cup coffee \n",
      "실제 요약 :  my new favorite \n",
      "예측 요약 :   delicious\n",
      "\n",
      "\n",
      "원문 :  guess best way review flavor mints cheap plastic like taste nothing special oz adequate desk candy \n",
      "실제 요약 :  what is there to say about mints \n",
      "예측 요약 :   not the best\n",
      "\n",
      "\n",
      "원문 :  get brand size bj half price shipping buy bags time good \n",
      "실제 요약 :  love mango \n",
      "예측 요약 :   not as good as the price\n",
      "\n",
      "\n",
      "원문 :  great go breakfast snack tastes good easy carry around would recommend anyone \n",
      "실제 요약 :  yummy snack \n",
      "예측 요약 :   great snack\n",
      "\n",
      "\n",
      "원문 :  one favorite flavors peppers seasoning packet pretty spicy price decent easy meal option buy cent store honestly amount getting would pay dollar things tasty bit different usual cup noodle \n",
      "실제 요약 :  spicy good \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  switching ar child spit lot less still spits formula life saver recommend \n",
      "실제 요약 :  really works \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  seemed like perfect way limit addiction potato chips small single serving bags really like plain unflavored popchips rest flavors aftertaste plan set subscribe save plain \n",
      "실제 요약 :  only like the plain ones \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  candy good flavor sour fizzy inside outside flavor kind remind jolly ranchers \n",
      "실제 요약 :  tasty candy sour and fizzy on \n",
      "예측 요약 :   not as good as the original\n",
      "\n",
      "\n",
      "원문 :  beans flavor depth loved every first open smell cocoa undertones beans well roasted \n",
      "실제 요약 :  yummy \n",
      "예측 요약 :   great coffee\n",
      "\n",
      "\n",
      "원문 :  love tastes great convenient use husband drinks car instead soda juice pour powder oz water bottle shake well directions box say use ml tea really strong use bottle kids love love whole food box costs tax get boxes price use still quite expensive well worth \n",
      "실제 요약 :  healthy refreshing tea for summer \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  really like shampoo lot required full head importantly softness shine gives hair hair fine years quite sure product makes hair look thicker appear body continue use product thank \n",
      "실제 요약 :  good product \n",
      "예측 요약 :   works great\n",
      "\n",
      "\n",
      "원문 :  brewer years jar crap got zero fermentation nothing jar dead yeast tried making starter two times nothing thing used nutrient actual good yeast \n",
      "실제 요약 :  jar of \n",
      "예측 요약 :   not the best\n",
      "\n",
      "\n",
      "원문 :  happy please entire process first time order keep ordering \n",
      "실제 요약 :  product \n",
      "예측 요약 :   great\n",
      "\n",
      "\n",
      "원문 :  got tea drink office delicious sour taste love color also beautiful high content vitamin say arrived promptly well packed hard find local store happy product seller \n",
      "실제 요약 :  delicious way to get your vitamin \n",
      "예측 요약 :   great tea\n",
      "\n",
      "\n",
      "원문 :  used able find local walmart stopped carrying happy could order amazon \n",
      "실제 요약 :  great decaf vanilla tea \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  somehow miracle found zico pure premium coconut water become preferred drink inflammation bladder since started drinking zico symptoms absolutely love chocolate flavor coconut chocolate best combination drink bottles day keeps feeling wonderful shopped around amazon com lowest price found buy great \n",
      "실제 요약 :  coconut water and my \n",
      "예측 요약 :   best coconut water ever\n",
      "\n",
      "\n",
      "원문 :  trying many different kinds pasta almost good wheat pasta used years \n",
      "실제 요약 :  darn good \n",
      "예측 요약 :   great pasta\n",
      "\n",
      "\n",
      "원문 :  best flavor hard find stores love \n",
      "실제 요약 :  raspberry gum \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  cat food seems like anything company puts hit house chicken soup lunch day kitty getting never seen cat go crazy food ton flavors keep mr happy going try whatever keeps finicky feline happy \n",
      "실제 요약 :  cat food \n",
      "예측 요약 :   my cat loves this\n",
      "\n",
      "\n",
      "원문 :  fantastic bacon hardly cooked pan full grease afterwards wife found smokey flavored taste thought great tried peppered bacon yet looking forward expensive bacon one reviewer complained something would every weekend occasional treat though probably best bacon ever \n",
      "실제 요약 :  fantastic bacon \n",
      "예측 요약 :   great taste\n",
      "\n",
      "\n",
      "원문 :  baby loves dinners flavorful bland like baby food tried love fact organic amazon sells great price \n",
      "실제 요약 :  my baby loves these \n",
      "예측 요약 :   baby loves it\n",
      "\n",
      "\n",
      "원문 :  taste flavoring put many drops water increasing make water sweet flavor understand others tasted flavoring sure wanted something natural would taste good drinking sugar water find something add flavor water work well tea since real flavor taste tea makes sweet enough \n",
      "실제 요약 :  what flavor \n",
      "예측 요약 :   not the best\n",
      "\n",
      "\n",
      "원문 :  many snacks labeled healthy today still hydrogenated oils garden eatin snacks taste wonderful great salsa guacamole sesame seeds add nice flavor without overpowering favorite chip occasions \n",
      "실제 요약 :  tasty and healthy \n",
      "예측 요약 :   great snack\n",
      "\n",
      "\n",
      "원문 :  buy online always burnt fur person loves wrote company said nothing wrong compared others definitely burnt \n",
      "실제 요약 :  burnt \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  never tried hibiscus tea flavor nice like mix lemonade cold also good hot tea tea nice flavored green black tea bag makes alot tea \n",
      "실제 요약 :  nice flavor \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :   great tea\n",
      "\n",
      "\n",
      "원문 :  two year dogs like prone major tartar build teeth helped made breath better never expected polish teeth perfectly made bad condition bad \n",
      "실제 요약 :  dogs liked em \n",
      "예측 요약 :   cet chews\n",
      "\n",
      "\n",
      "원문 :  recommended vets seen healthy clean teeth dog loves cut half though eats whole one tummy like sensitive stomach though \n",
      "실제 요약 :  dog loves them \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  gold delicious organic product healthy preparation quick simple make also add another cups sprouted quinoa make dish larger good neighbors loved \n",
      "실제 요약 :  the best \n",
      "예측 요약 :   great product\n",
      "\n",
      "\n",
      "원문 :  delivery fast best coffee lovers great tasting coffee would recommend everyone excellent gift coffee drinker \n",
      "실제 요약 :  yumm coffee \n",
      "예측 요약 :   great coffee\n",
      "\n",
      "\n",
      "원문 :  creamer fine creamers exploded box problem break open left whole box covered sticky go hand wash putting staff clients simply irritating \n",
      "실제 요약 :  milk \n",
      "예측 요약 :   not what expected\n",
      "\n",
      "\n",
      "원문 :  first time tried brand love tried vita coco brands ok taste fact tasted flat stale brand fresh delicious enjoying much also tried brand taste similar would buy zico zico little cheaper great deal \n",
      "실제 요약 :  taste fresh and so delish \n",
      "예측 요약 :   not the best\n",
      "\n",
      "\n",
      "원문 :  sure company thinking packaged half mine arrived leaking make matters worse ones opened tasted horrible way sweet ordered brands much happier packaging taste value never reorder \n",
      "실제 요약 :  horrible packaging and taste \n",
      "예측 요약 :   not bad\n",
      "\n",
      "\n",
      "원문 :  product sweet also use nectar find sweeter looking something take place granular sugar think right stick nectar trying get away sweet low splenda \n",
      "실제 요약 :  natural sweetner \n",
      "예측 요약 :   good stuff\n",
      "\n",
      "\n",
      "원문 :  family always loved black hard find area reason started using old fashioned bagged pop corn using covered skillet stove like microwave type try tell anyone family something different watch reactions popcorn huge popped kernals like regular yellow corn lot flavor \n",
      "실제 요약 :  old style popcorn taste \n",
      "예측 요약 :   great for on the go\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 : \", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 : \", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 : \", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오...... 많은 결과를 출력해보았는데, 조금 어색한 요약도 조금 보이지만 잘 맞는 요약도 보이기도 합니다. 어떤 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하기도 하고있습니다. \n",
    "\n",
    "성능을 개선하기 위해서는 seq2seq와 어텐션 자체의 조합을 좀 더 좋게 수정하는 방법도 있고, 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더-디코더 자체의 구조를 새로이 변경하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재합니다. \n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "> 번외 - 추출적 요약 해보기\n",
    "\n",
    "지금까지 추상적 요약을 살펴보았습니다. 이번에는 한번 추출적 요약도 살펴봅시다.\n",
    "\n",
    "패키지 `Summa`에서는 추출적 요약을 위한 모듈인 `summarize`를 제공하고 있어 아주 간단하게 실습을 해볼 수 있습니다. 영화 매트릭스의 시놉시스를 요약해보면서 summarize를 한번 사용해봅시다!\n",
    "\n",
    "\n",
    "### 패키지 설치\n",
    "\n",
    "먼저 아래 명령어를 입력하여 패키지를 설치해줍니다.\n",
    "\n",
    "```bash\n",
    "$ pip install summa\n",
    "```\n",
    "\n",
    "### 데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 불ㄹ러옵시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 text에는 매트릭스 시놉시스가 문자열로 저장되어져 있어요. 출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize 사용하기\n",
    "\n",
    "`Summa`의 `summarize()`의 인자로 사용되는 값들에 대해서 가볍게 살펴봅시다.\n",
    "\n",
    "- text(str) : 요약할 텍스트\n",
    "- ratio (float, optional) : 요약문 원본에서 선택되는 문장 비율. 0~1사이의 값\n",
    "- words (int or None, optional) : 출력에 포함할 단어의 수. 만약 ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.\n",
    "- split (bool, optional) : True면 문장 list, False는 조인된 문자열을 반환\n",
    "\n",
    "Summa의 Summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행합니다. 그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있습니다. 비율을 적게 주어서 요약문으로 선택되는 문장의 갯수를 줄여봅시다. 원문의 0.005%만을 출력하도록 설정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary\")\n",
    "print(summarize(text, ratio = 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 하면 돼요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary\")\n",
    "print(summarize(text, ratio = 0.005, split = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 수로 요약문의 크기를 조절할수도 있습니다. 50개만 선택해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary\")\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 텍스트 요약에 대해서 알아보았습니다. :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
